[2025-09-08 16:10:40] Loading model: mistralai/Mistral-7B-Instruct-v0.2, tp=1, dtype=auto
[2025-09-08 16:14:09] Loading model: mistralai/Mistral-7B-Instruct-v0.2, tp=1, dtype=auto, gpu_mem_util=0.5, max_model_len=2048, max_num_seqs=2, enforce_eager=True
[2025-09-08 16:14:45] Running warmup...
[2025-09-08 16:20:55] Loading model: mistralai/Mistral-7B-Instruct-v0.2, tp=1, dtype=auto, gpu_mem_util=0.5, max_model_len=2048, max_num_seqs=2, enforce_eager=True, max_num_batched_tokens=4096, concurrency_mode=batched
[2025-09-08 16:21:27] Running warmup...
[2025-09-08 16:21:30] Total E2E time (2 requests, batched): 1.3834 s
[2025-09-08 16:23:39] Loading model: mistralai/Mistral-7B-Instruct-v0.2, tp=1, dtype=auto, gpu_mem_util=0.5, max_model_len=2048, max_num_seqs=2, enforce_eager=True, max_num_batched_tokens=4096, concurrency_mode=batched
[2025-09-08 16:24:13] Running warmup...
[2025-09-08 16:24:17] Serial total E2E time (2 requests): 2.2467 s
[2025-09-08 16:24:17] Parallel total E2E time (2 requests, batched): 1.1828 s
[2025-09-08 16:24:17] Serial: 2.2467s | Parallel(batched): 1.1828s | Speedup: 1.90x
[2025-09-08 16:26:52] Loading model: mistralai/Mistral-7B-Instruct-v0.2, tp=1, dtype=auto, gpu_mem_util=0.5, max_model_len=2048, max_num_seqs=2, enforce_eager=True, max_num_batched_tokens=4096, concurrency_mode=batched, repeats=100
[2025-09-08 16:27:26] Running warmup...
[2025-09-08 16:33:26] Serial total time for 100 runs (2 tasks/run): 239.0272 s
[2025-09-08 16:33:26] Serial average per task: 1.1951 s
[2025-09-08 16:33:26] Parallel total time for 100 runs (2 tasks/run, batched): 120.1373 s
[2025-09-08 16:33:26] Parallel average per task: 0.6007 s
[2025-09-08 16:33:26] Serial: total=239.0272s, avg_task=1.1951s | Parallel(batched): total=120.1373s, avg_task=0.6007s | Speedup: 1.99x
